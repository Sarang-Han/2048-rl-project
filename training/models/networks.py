import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Tuple

class CNN2048Network(nn.Module):
    """2048ìš© CNN ë„¤íŠ¸ì›Œí¬ - ê°œì„ ëœ ë²„ì „"""
    
    def __init__(self, input_channels: int = 16, hidden_dim: int = 512):
        super(CNN2048Network, self).__init__()
        
        # Convolutional layers - ê¸°ì¡´ ìœ ì§€í•˜ë˜ BatchNorm ì¶”ê°€
        self.conv1 = nn.Conv2d(input_channels, 128, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)
        
        # BatchNorm ì¶”ê°€ (DDQN ì½”ë“œì˜ ì¥ì )
        self.bn1 = nn.BatchNorm2d(128)
        self.bn2 = nn.BatchNorm2d(128)
        self.bn3 = nn.BatchNorm2d(128)
        
        # ê¸°ì¡´ FC ë ˆì´ì–´ êµ¬ì¡° ìœ ì§€
        conv_output_size = 4 * 4 * 128
        self.fc1 = nn.Linear(conv_output_size, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.fc3 = nn.Linear(hidden_dim, 4)
        
        # Dropout ì¶”ê°€ (ì•ˆì •ì„± í–¥ìƒ)
        self.dropout = nn.Dropout(0.1)
        
        # ê°œì„ ëœ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        self._initialize_weights()
    
    def _initialize_weights(self):
        """Kaiming ì´ˆê¸°í™” ì ìš©"""
        for module in self.modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
            elif isinstance(module, nn.Linear):
                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')
                nn.init.constant_(module.bias, 0)
            elif isinstance(module, nn.BatchNorm2d):
                nn.init.constant_(module.weight, 1)
                nn.init.constant_(module.bias, 0)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """ìˆœì „íŒŒ - BatchNorm ì ìš©"""
        # ì°¨ì› ë³€í™˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        if x.dim() == 4 and x.shape[-1] == 16:
            x = x.permute(0, 3, 1, 2)
        
        # Conv layers with BatchNorm
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.relu(self.bn2(self.conv2(x)))
        x = F.relu(self.bn3(self.conv3(x)))
        
        # Flatten
        x = torch.flatten(x, start_dim=1)
        
        # FC layers with Dropout
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        
        return x

# ê¸°ì¡´ í•¨ìˆ˜ë“¤ ìœ ì§€í•˜ë˜ Dueling ì˜µì…˜ ì¶”ê°€
class DuelingDQNNetwork(nn.Module):
    """Dueling DQN - ì„ íƒì  ì ìš©"""
    
    def __init__(self, base_network: nn.Module):
        super(DuelingDQNNetwork, self).__init__()
        
        self.base_network = base_network
        
        # ë§ˆì§€ë§‰ ë ˆì´ì–´ ì œê±°í•˜ê³  Dueling head ì¶”ê°€
        hidden_dim = base_network.fc2.out_features
        base_network.fc3 = nn.Identity()
        
        # Valueì™€ Advantage stream
        self.value_head = nn.Linear(hidden_dim, 1)
        self.advantage_head = nn.Linear(hidden_dim, 4)
        
        # ì´ˆê¸°í™”
        nn.init.kaiming_normal_(self.value_head.weight, mode='fan_out', nonlinearity='relu')
        nn.init.constant_(self.value_head.bias, 0)
        nn.init.kaiming_normal_(self.advantage_head.weight, mode='fan_out', nonlinearity='relu')
        nn.init.constant_(self.advantage_head.bias, 0)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        features = self.base_network(x)
        
        value = self.value_head(features)
        advantage = self.advantage_head(features)
        
        # Dueling ê³µì‹
        q_values = value + advantage - advantage.mean(dim=1, keepdim=True)
        return q_values

def create_network(use_dueling: bool = False, **kwargs) -> nn.Module:
    """ë„¤íŠ¸ì›Œí¬ íŒ©í† ë¦¬ í•¨ìˆ˜ - ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€"""
    base_net = CNN2048Network(**kwargs)
    
    if use_dueling:
        return DuelingDQNNetwork(base_net)
    else:
        return base_net

# ê¸°ì¡´ í•¨ìˆ˜ë“¤ ìœ ì§€
def count_parameters(model: nn.Module) -> int:
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

# ë„¤íŠ¸ì›Œí¬ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_networks():
    """ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§  Neural Networks í…ŒìŠ¤íŠ¸")
    
    try:
        # CNN ë„¤íŠ¸ì›Œí¬ í…ŒìŠ¤íŠ¸ (Layered ê´€ì°°)
        print("\n1. CNN Network (Layered observation):")
        cnn_net_dueling = create_network(use_dueling=True)
        cnn_net_simple = create_network(use_dueling=False)

        print(f"   - Dueling íŒŒë¼ë¯¸í„° ìˆ˜: {count_parameters(cnn_net_dueling):,}")
        print(f"   - Non-Dueling íŒŒë¼ë¯¸í„° ìˆ˜: {count_parameters(cnn_net_simple):,}")
        
        # í…ŒìŠ¤íŠ¸ ì…ë ¥
        layered_input = torch.randn(32, 4, 4, 16)  # batch_size=32
        print(f"   - ì…ë ¥ shape: {layered_input.shape}")
        
        cnn_output = cnn_net_dueling(layered_input)
        print(f"   - ì¶œë ¥ shape: {cnn_output.shape}")
        print(f"   - ì¶œë ¥ ë²”ìœ„: [{cnn_output.min():.3f}, {cnn_output.max():.3f}]")
        
        print("\nâœ… ëª¨ë“  ë„¤íŠ¸ì›Œí¬ê°€ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•©ë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_networks()
