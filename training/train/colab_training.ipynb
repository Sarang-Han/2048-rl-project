{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "70268a27",
      "metadata": {
        "id": "70268a27"
      },
      "source": [
        "# 2048 DQN 모델 학습\n",
        "\n",
        "## 학습 계획\n",
        "- **목적**: 2048 게임에서 고득점을 달성하는 CNN 기반 DQN 에이전트 학습\n",
        "- **아키텍처**: CNN (Layered)\n",
        "- **환경**: Google Colab GPU 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd0f131c",
      "metadata": {
        "id": "cd0f131c"
      },
      "source": [
        "## 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ea4d482",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ea4d482",
        "outputId": "53deeb4c-75d6-41a9-ce45-fbeb1e371c40"
      },
      "outputs": [],
      "source": [
        "# 필요한 패키지 설치\n",
        "!pip install torch torchvision gym matplotlib seaborn tensorboard\n",
        "!pip install onnx onnxruntime\n",
        "\n",
        "import torch\n",
        "print(f\"PyTorch 버전: {torch.__version__}\")\n",
        "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2aa566b",
      "metadata": {
        "id": "a2aa566b"
      },
      "source": [
        "## 코드 업로드 및 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93e40528",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93e40528",
        "outputId": "f61d4581-0161-4846-a3bc-4f5bd3c284c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "✅ 경로 설정 완료!\n",
            "  프로젝트 루트: /content/drive/MyDrive/2048-rl-project\n",
            "  학습 경로: /content/drive/MyDrive/2048-rl-project/training\n",
            "  현재 작업 디렉토리: /content/drive/MyDrive/2048-rl-project/training\n"
          ]
        }
      ],
      "source": [
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# 프로젝트 경로 설정\n",
        "PROJECT_ROOT = '/content/drive/MyDrive/2048-rl-project'\n",
        "TRAINING_PATH = os.path.join(PROJECT_ROOT, 'training')\n",
        "\n",
        "# Python 경로에 추가\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "if TRAINING_PATH not in sys.path:\n",
        "    sys.path.insert(0, TRAINING_PATH)\n",
        "\n",
        "# 작업 디렉토리 변경\n",
        "os.chdir(TRAINING_PATH)\n",
        "\n",
        "print(f\"✅ 경로 설정 완료!\")\n",
        "print(f\"  프로젝트 루트: {PROJECT_ROOT}\")\n",
        "print(f\"  학습 경로: {TRAINING_PATH}\")\n",
        "print(f\"  현재 작업 디렉토리: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a1d7c58",
      "metadata": {
        "id": "1a1d7c58"
      },
      "source": [
        "## 모델 및 환경 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d975255d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d975255d",
        "outputId": "cde93c47-5b7e-425e-c783-e662a3e3521e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 모듈 로딩 시작...\n",
            "✅ Environment 패키지 로드 완료 - 지원 관찰 타입: ['layered']\n",
            "✅ Models 패키지 로드 완료 - 지원 네트워크: ['layered']\n",
            "✅ 모듈 로드 완료\n"
          ]
        }
      ],
      "source": [
        "# 모듈 import 및 테스트\n",
        "print(\"🔄 모듈 로딩 시작...\")\n",
        "\n",
        "from environment.game_2048 import Game2048Env\n",
        "from models.dqn_agent import DQNAgent\n",
        "from models.networks import count_parameters\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "\n",
        "print(\"✅ 모듈 로드 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1de60ca",
      "metadata": {
        "id": "c1de60ca"
      },
      "source": [
        "## 학습 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb624383",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb624383",
        "outputId": "42e20213-5ba7-49ab-8872-9a03fc8e93de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚙️ 학습 설정 완료:\n",
            "  episodes: 2000\n",
            "  max_steps_per_episode: 1000\n",
            "  device: cuda\n",
            "  buffer_size: 100000\n",
            "  batch_size: 64\n",
            "  lr: 0.0001\n",
            "  gamma: 0.99\n",
            "  epsilon_start: 1.0\n",
            "  epsilon_end: 0.01\n",
            "  epsilon_decay: 50000\n",
            "  target_update: 1000\n",
            "  eval_interval: 100\n",
            "  eval_episodes: 10\n",
            "  save_interval: 500\n",
            "  plot_interval: 50\n",
            "  log_interval: 10\n"
          ]
        }
      ],
      "source": [
        "TRAINING_CONFIG = {\n",
        "    # 기본 설정\n",
        "    'episodes': 2000,\n",
        "    'max_steps_per_episode': 1000,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "\n",
        "    # DQN 설정\n",
        "    'buffer_size': 100000,\n",
        "    'batch_size': 64,\n",
        "    'lr': 1e-4,\n",
        "    'gamma': 0.99,\n",
        "    'epsilon_start': 0.9,\n",
        "    'epsilon_end': 0.01,\n",
        "    'epsilon_decay': 30000,\n",
        "    'target_update': 1000,\n",
        "\n",
        "    # 평가 및 로깅 설정\n",
        "    'eval_interval': 100,\n",
        "    'eval_episodes': 10,\n",
        "    'save_interval': 500,\n",
        "    'plot_interval': 50,\n",
        "    'log_interval': 10\n",
        "}\n",
        "\n",
        "print(\"⚙️ 학습 설정 완료:\")\n",
        "for key, value in TRAINING_CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c94975f",
      "metadata": {
        "id": "9c94975f"
      },
      "source": [
        "## 모델 초기화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17fa33dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17fa33dd",
        "outputId": "3d636bab-2dd4-4cec-bf75-01c551263cef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧠 CNN 에이전트 생성...\n",
            "🤖 DQN Agent 초기화 - Device: cuda\n",
            "🤖 DQN Agent 초기화 완료\n",
            "   - Double DQN: True\n",
            "   - Dueling DQN: False\n",
            "   - Prioritized Replay: True\n",
            "📊 모델 파라미터: 1,628,292\n"
          ]
        }
      ],
      "source": [
        "# 개선된 에이전트 생성 함수\n",
        "def create_agent_and_env():\n",
        "    \"\"\"개선된 에이전트와 환경 생성\"\"\"\n",
        "    env = Game2048Env()\n",
        "\n",
        "    agent = DQNAgent(\n",
        "        lr=TRAINING_CONFIG['lr'],\n",
        "        gamma=TRAINING_CONFIG['gamma'],\n",
        "        epsilon_start=TRAINING_CONFIG['epsilon_start'],\n",
        "        epsilon_end=TRAINING_CONFIG['epsilon_end'],\n",
        "        epsilon_decay=TRAINING_CONFIG['epsilon_decay'],\n",
        "        buffer_size=TRAINING_CONFIG['buffer_size'],\n",
        "        batch_size=TRAINING_CONFIG['batch_size'],\n",
        "        target_update=TRAINING_CONFIG['target_update'],\n",
        "        double_dqn=True,           # Double DQN 활성화\n",
        "        dueling=False,             # dueling head 활성화 여부\n",
        "        prioritized_replay=True,   # 성능 향상\n",
        "        device=TRAINING_CONFIG['device']\n",
        "    )\n",
        "\n",
        "    return agent, env\n",
        "\n",
        "print(\"🧠 CNN 에이전트 생성...\")\n",
        "agent, env = create_agent_and_env()\n",
        "print(f\"📊 모델 파라미터: {count_parameters(agent.q_network):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e08891f",
      "metadata": {
        "id": "9e08891f"
      },
      "source": [
        "## 학습 모니터링 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6faa7ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6faa7ae",
        "outputId": "5221f46c-21f0-41d2-f2b1-ddf8bacb508e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 학습 모니터링 시스템 준비 완료!\n"
          ]
        }
      ],
      "source": [
        "class TrainingMonitor:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.episode_rewards = []\n",
        "        self.episode_scores = []\n",
        "        self.episode_steps = []\n",
        "        self.episode_losses = []\n",
        "        self.highest_tiles = []\n",
        "        self.eval_scores = []\n",
        "        self.eval_episodes = []\n",
        "\n",
        "    def add_episode(self, reward, score, steps, loss, highest_tile):\n",
        "        self.episode_rewards.append(reward)\n",
        "        self.episode_scores.append(score)\n",
        "        self.episode_steps.append(steps)\n",
        "        self.episode_losses.append(loss)\n",
        "        self.highest_tiles.append(highest_tile)\n",
        "\n",
        "    def add_eval(self, episode, avg_score):\n",
        "        self.eval_episodes.append(episode)\n",
        "        self.eval_scores.append(avg_score)\n",
        "\n",
        "    def plot_progress(self, title=\"Training Progress\"):\n",
        "        if len(self.episode_rewards) < 10:\n",
        "            return\n",
        "\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        fig.suptitle(title, fontsize=16)\n",
        "\n",
        "        # 보상\n",
        "        axes[0,0].plot(self.episode_rewards, alpha=0.3, color='blue')\n",
        "        axes[0,0].plot(pd.Series(self.episode_rewards).rolling(50).mean(), color='red')\n",
        "        axes[0,0].set_title('Episode Rewards')\n",
        "        axes[0,0].set_ylabel('Reward')\n",
        "\n",
        "        # 점수\n",
        "        axes[0,1].plot(self.episode_scores, alpha=0.3, color='green')\n",
        "        axes[0,1].plot(pd.Series(self.episode_scores).rolling(50).mean(), color='red')\n",
        "        axes[0,1].set_title('Episode Scores')\n",
        "        axes[0,1].set_ylabel('Score')\n",
        "\n",
        "        # 최고 타일\n",
        "        axes[0,2].plot(self.highest_tiles, alpha=0.3, color='purple')\n",
        "        axes[0,2].plot(pd.Series(self.highest_tiles).rolling(50).mean(), color='red')\n",
        "        axes[0,2].set_title('Highest Tiles')\n",
        "        axes[0,2].set_ylabel('Tile Value')\n",
        "\n",
        "        # 스텝 수\n",
        "        axes[1,0].plot(self.episode_steps, alpha=0.3, color='orange')\n",
        "        axes[1,0].plot(pd.Series(self.episode_steps).rolling(50).mean(), color='red')\n",
        "        axes[1,0].set_title('Episode Steps')\n",
        "        axes[1,0].set_ylabel('Steps')\n",
        "        axes[1,0].set_xlabel('Episode')\n",
        "\n",
        "        # 손실\n",
        "        if self.episode_losses and any(loss is not None for loss in self.episode_losses):\n",
        "            valid_losses = [l for l in self.episode_losses if l is not None]\n",
        "            if valid_losses:\n",
        "                axes[1,1].plot(valid_losses, alpha=0.3, color='red')\n",
        "                axes[1,1].plot(pd.Series(valid_losses).rolling(20).mean(), color='darkred')\n",
        "        axes[1,1].set_title('Training Loss')\n",
        "        axes[1,1].set_ylabel('Loss')\n",
        "        axes[1,1].set_xlabel('Episode')\n",
        "\n",
        "        # 평가 점수\n",
        "        if self.eval_scores:\n",
        "            axes[1,2].plot(self.eval_episodes, self.eval_scores, 'o-', color='darkgreen')\n",
        "        axes[1,2].set_title('Evaluation Scores')\n",
        "        axes[1,2].set_ylabel('Avg Score')\n",
        "        axes[1,2].set_xlabel('Episode')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def get_stats(self):\n",
        "        if not self.episode_scores:\n",
        "            return {}\n",
        "\n",
        "        recent_scores = self.episode_scores[-100:]\n",
        "        recent_tiles = self.highest_tiles[-100:]\n",
        "\n",
        "        return {\n",
        "            'episodes': len(self.episode_scores),\n",
        "            'avg_score': np.mean(recent_scores),\n",
        "            'max_score': max(self.episode_scores),\n",
        "            'avg_highest_tile': np.mean(recent_tiles),\n",
        "            'max_highest_tile': max(self.highest_tiles),\n",
        "            'avg_steps': np.mean(self.episode_steps[-100:])\n",
        "        }\n",
        "\n",
        "monitor = TrainingMonitor()\n",
        "print(\"📊 학습 모니터링 시스템 준비 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3d8e403",
      "metadata": {
        "id": "e3d8e403"
      },
      "source": [
        "## 학습 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a1a6fb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a1a6fb7",
        "outputId": "c43b669a-0e97-46a5-b214-b885dee5183e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 학습 함수 로드 완료!\n"
          ]
        }
      ],
      "source": [
        "def evaluate_agent(agent, env, num_episodes=5):\n",
        "    \"\"\"액션 마스킹이 적용된 에이전트 평가 함수\"\"\"\n",
        "    total_scores = []\n",
        "    total_steps = []\n",
        "    highest_tiles = []\n",
        "    \n",
        "    for _ in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        steps = 0\n",
        "        while steps < 1000:\n",
        "            # 🔥 액션 마스킹 적용\n",
        "            valid_actions = env.get_valid_actions()\n",
        "            if not valid_actions:  # 게임 종료 (안전장치)\n",
        "                break\n",
        "                \n",
        "            action = agent.select_action(state, training=False, valid_actions=valid_actions)\n",
        "            next_state, _, done, info = env.step(action)\n",
        "            state = next_state\n",
        "            steps += 1\n",
        "            \n",
        "            if done:\n",
        "                total_scores.append(info['score'])\n",
        "                total_steps.append(steps)\n",
        "                highest_tiles.append(info['highest'])\n",
        "                break\n",
        "    \n",
        "    return {\n",
        "        'avg_score': np.mean(total_scores) if total_scores else 0,\n",
        "        'avg_steps': np.mean(total_steps) if total_steps else 0,\n",
        "        'avg_highest': np.mean(highest_tiles) if highest_tiles else 0,\n",
        "        'max_score': max(total_scores) if total_scores else 0,\n",
        "        'max_highest': max(highest_tiles) if highest_tiles else 0\n",
        "    }\n",
        "\n",
        "def train_agent(agent, env, monitor, episodes):\n",
        "    \"\"\"액션 마스킹이 적용된 에이전트 학습 함수 (수정된 버전)\"\"\"\n",
        "    print(f\"🚀 액션 마스킹 적용 CNN 모델 학습 시작! (목표: {episodes} 에피소드)\")\n",
        "    start_time = time.time()\n",
        "    best_score = 0\n",
        "    best_highest = 0\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        state = env.reset()\n",
        "        total_reward = 0\n",
        "        steps = 0\n",
        "        episode_losses = []\n",
        "        final_info = {'score': 0, 'highest': 0, 'valid_actions': []}  # 기본값 설정\n",
        "\n",
        "        while steps < TRAINING_CONFIG['max_steps_per_episode']:\n",
        "            # 🔥 액션 마스킹 적용\n",
        "            valid_actions = env.get_valid_actions()\n",
        "            \n",
        "            # 유효한 액션이 없으면 게임 종료\n",
        "            if not valid_actions:\n",
        "                print(f\"⚠️ Episode {episode+1}: No valid actions available at step {steps}\")\n",
        "                break\n",
        "            \n",
        "            # 액션 선택 (유효한 액션만 고려)\n",
        "            action = agent.select_action(state, training=True, valid_actions=valid_actions)\n",
        "            \n",
        "            # 환경에서 액션 실행\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            final_info = info  # 마지막 info 저장\n",
        "            \n",
        "            # 경험 저장\n",
        "            if hasattr(agent, 'prioritized_replay') and agent.prioritized_replay and agent.memory.is_ready(agent.batch_size):\n",
        "                # TD error 미리 계산\n",
        "                with torch.no_grad():\n",
        "                    state_tensor = torch.FloatTensor(state).unsqueeze(0).to(agent.device)\n",
        "                    next_state_tensor = torch.FloatTensor(next_state).unsqueeze(0).to(agent.device)\n",
        "                    current_q = agent.q_network(state_tensor)[0][action]\n",
        "                    next_q = agent.target_network(next_state_tensor).max(1)[0]\n",
        "                    target_q = reward + (agent.gamma * next_q * (not done))\n",
        "                    td_error = abs((target_q - current_q).item())\n",
        "                    agent.store_experience(state, action, reward, next_state, done, td_error)\n",
        "            else:\n",
        "                agent.store_experience(state, action, reward, next_state, done)\n",
        "\n",
        "            # 학습 수행\n",
        "            if agent.memory.is_ready(agent.batch_size):\n",
        "                loss = agent.train_step()\n",
        "                if loss is not None:\n",
        "                    episode_losses.append(loss)\n",
        "\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            steps += 1\n",
        "            \n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # 에피소드 통계 업데이트\n",
        "        avg_loss = np.mean(episode_losses) if episode_losses else None\n",
        "        monitor.add_episode(total_reward, final_info['score'], steps, avg_loss, final_info['highest'])\n",
        "        agent.episode_rewards.append(total_reward)\n",
        "\n",
        "        # 최고 기록 갱신\n",
        "        if final_info['score'] > best_score:\n",
        "            best_score = final_info['score']\n",
        "            agent.save_model(f'/content/drive/MyDrive/2048_models/cnn_model_best_score.pth')\n",
        "            \n",
        "        if final_info['highest'] > best_highest:\n",
        "            best_highest = final_info['highest']\n",
        "            agent.save_model(f'/content/drive/MyDrive/2048_models/cnn_model_best_tile.pth')\n",
        "\n",
        "        # 주기적 로깅\n",
        "        if (episode + 1) % TRAINING_CONFIG['log_interval'] == 0:\n",
        "            stats = agent.get_stats()\n",
        "            elapsed = time.time() - start_time\n",
        "            loss_str = f\"{avg_loss:.4f}\" if avg_loss is not None else \"N/A\"\n",
        "            \n",
        "            print(f\"Episode {episode+1:4d} | Score: {final_info['score']:5.0f} | Highest: {final_info['highest']:4.0f} | \"\n",
        "                  f\"Reward: {total_reward:7.2f} | Steps: {steps:3d} | Valid: {len(final_info['valid_actions'])} | \"\n",
        "                  f\"ε: {stats['epsilon']:.3f} | Loss: {loss_str} | Time: {elapsed/60:.1f}min\")\n",
        "            \n",
        "        if (episode + 1) % TRAINING_CONFIG['eval_interval'] == 0:\n",
        "            eval_results = evaluate_agent(agent, env, TRAINING_CONFIG['eval_episodes'])\n",
        "            monitor.add_eval(episode + 1, eval_results['avg_score'])\n",
        "            \n",
        "            print(f\"🎯 평가 결과 (Episode {episode+1}):\")\n",
        "            print(f\"   평균 점수: {eval_results['avg_score']:.1f}\")\n",
        "            print(f\"   최고 점수: {eval_results['max_score']:.0f}\")\n",
        "            print(f\"   평균 최고타일: {eval_results['avg_highest']:.0f}\")\n",
        "            print(f\"   최고 타일: {eval_results['max_highest']:.0f}\")\n",
        "\n",
        "        # 주기적 시각화\n",
        "        if (episode + 1) % TRAINING_CONFIG['plot_interval'] == 0:\n",
        "            clear_output(wait=True)\n",
        "            monitor.plot_progress(f\"CNN Training Progress - Episode {episode+1}\")\n",
        "            \n",
        "            stats = monitor.get_stats()\n",
        "            print(f\"📊 현재 통계 (최근 100 에피소드):\")\n",
        "            for key, value in stats.items():\n",
        "                if isinstance(value, float):\n",
        "                    print(f\"  {key}: {value:.2f}\")\n",
        "                else:\n",
        "                    print(f\"  {key}: {value}\")\n",
        "            \n",
        "            print(f\"  현재 epsilon: {agent.get_epsilon():.4f}\")\n",
        "            print(f\"  메모리 사용량: {len(agent.memory):,}/{agent.memory.capacity:,}\")\n",
        "\n",
        "        # 주기적 모델 저장\n",
        "        if (episode + 1) % TRAINING_CONFIG['save_interval'] == 0:\n",
        "            agent.save_model(f'/content/drive/MyDrive/2048_models/cnn_checkpoint_{episode+1}.pth')\n",
        "\n",
        "    # 최종 모델 저장\n",
        "    agent.save_model(f'/content/drive/MyDrive/2048_models/cnn_final_action_masked.pth')\n",
        "    \n",
        "    print(f\"\\n✅ 액션 마스킹 적용 학습 완료!\")\n",
        "    print(f\"🏆 최고 점수: {best_score}\")\n",
        "    print(f\"🎯 최고 타일: {best_highest}\")\n",
        "    \n",
        "    return monitor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f35c846c",
      "metadata": {
        "id": "f35c846c"
      },
      "source": [
        "## CNN 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73bf4881",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "id": "73bf4881",
        "outputId": "015c3dff-d775-45d5-cd1a-7f201d50c56b"
      },
      "outputs": [],
      "source": [
        "monitor = train_agent(\n",
        "    agent=agent,\n",
        "    env=env,\n",
        "    monitor=monitor,\n",
        "    episodes=TRAINING_CONFIG['episodes']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0191a35b",
      "metadata": {
        "id": "0191a35b"
      },
      "source": [
        "## 🏆 최종 성능 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff302daf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff302daf",
        "outputId": "78c7c80d-e41a-4e72-9fc8-77a8c747b339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏆 최종 성능 평가 (50 게임)\n",
            "📊 최종 평균 점수: 572.4\n",
            "📈 최종 학습 통계:\n",
            "  episodes: 2000\n",
            "  avg_score: 716.32\n",
            "  max_score: 2548\n",
            "  avg_highest_tile: 77.12\n",
            "  max_highest_tile: 256\n",
            "  avg_steps: 90.04\n"
          ]
        }
      ],
      "source": [
        "print(\"🏆 최종 성능 평가 (50 게임)\")\n",
        "final_results = evaluate_agent(agent, env, 50)\n",
        "print(f\"📊 최종 평균 점수: {final_results['avg_score']:.1f}\")\n",
        "print(f\"🏆 최고 점수: {final_results['max_score']:.0f}\")\n",
        "print(f\"🎯 평균 최고 타일: {final_results['avg_highest']:.0f}\")\n",
        "print(f\"🌟 최고 타일: {final_results['max_highest']:.0f}\")\n",
        "\n",
        "stats = monitor.get_stats()\n",
        "print(\"\\n📈 최종 학습 통계:\")\n",
        "for key, value in stats.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"  {key}: {value:.2f}\")\n",
        "    else:\n",
        "        print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fff8962",
      "metadata": {
        "id": "0fff8962"
      },
      "source": [
        "## ONNX 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc0b97a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc0b97a7",
        "outputId": "12ccaca5-9101-418c-d0d5-4675fa248d0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 ONNX 변환 시작...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/2048-rl-project/training/models/networks.py:52: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if x.dim() == 4 and x.shape[-1] == 16:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 ONNX 모델 내보내기 완료: /content/drive/MyDrive/2048_models/cnn_model.onnx\n",
            "✅ ONNX 변환 완료!\n"
          ]
        }
      ],
      "source": [
        "print(\"🔄 ONNX 변환 시작...\")\n",
        "agent.export_to_onnx(\n",
        "    filepath='/content/drive/MyDrive/2048_models/cnn_model.onnx',\n",
        "    input_shape=(4, 4, 16)\n",
        ")\n",
        "print(\"✅ ONNX 변환 완료!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
